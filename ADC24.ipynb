{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6ca6200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "directory = r\"G:\\data\\ariel-data-challenge-2024\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac09e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f_read_and_preprocess\n",
    "\n",
    "def f_read_and_preprocess(dataset, adc_info, planet_ids):\n",
    "    \"\"\"Read the FGS1 files for all planet_ids and extract the time series.\n",
    "    \n",
    "    Parameters\n",
    "    dataset: 'train' or 'test'\n",
    "    adc_info: metadata dataframe, either train_adc_info or test_adc_info\n",
    "    planet_ids: list of planet ids\n",
    "    \n",
    "    Returns\n",
    "    dataframe with one row per planet_id and 67500 values per row\n",
    "    \n",
    "    \"\"\"\n",
    "    f_raw_train = np.full((len(planet_ids), 67500), np.nan, dtype=np.float32)\n",
    "    for i, planet_id in tqdm(list(enumerate(planet_ids))):\n",
    "        f_signal = pl.read_parquet(r'G:\\data\\ariel-data-challenge-2024/{dataset}/{planet_id}/FGS1_signal.parquet')\n",
    "        mean_signal = f_signal.cast(pl.Int32).sum_horizontal().cast(pl.Float32).to_numpy() / 1024 # mean over the 32*32 pixels\n",
    "        net_signal = mean_signal[1::2] - mean_signal[0::2]\n",
    "        f_raw_train[i] = net_signal\n",
    "    return f_raw_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a4ee3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_read_and_preprocess\n",
    "def a_read_and_preprocess(dataset, adc_info, planet_ids):\n",
    "    \"\"\"Read the AIRS-CH0 files for all planet_ids and extract the time series.\n",
    "    \n",
    "    Parameters\n",
    "    dataset: 'train' or 'test'\n",
    "    adc_info: metadata dataframe, either train_adc_info or test_adc_info\n",
    "    planet_ids: list of planet ids\n",
    "    \n",
    "    Returns\n",
    "    dataframe with one row per planet_id and 5625 values per row\n",
    "    \n",
    "    \"\"\"\n",
    "    a_raw_train = np.full((len(planet_ids), 5625), np.nan, dtype=np.float32)\n",
    "    for i, planet_id in tqdm(list(enumerate(planet_ids))):\n",
    "        signal = pl.read_parquet(r'G:\\data\\ariel-data-challenge-2024/{dataset}/{planet_id}/AIRS-CH0_signal.parquet')\n",
    "        mean_signal = signal.cast(pl.Int32).sum_horizontal().cast(pl.Float32).to_numpy() / (32*356) # mean over the 32*356 pixels\n",
    "        net_signal = mean_signal[1::2] - mean_signal[0::2]\n",
    "        a_raw_train[i] = net_signal\n",
    "    return a_raw_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3393714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_engineering\n",
    "def feature_engineering(f_raw, a_raw):\n",
    "    \"\"\"Create a dataframe with two features from the raw data.\n",
    "    \n",
    "    Parameters:\n",
    "    f_raw: ndarray of shape (n_planets, 67500)\n",
    "    a_raw: ndarray of shape (n_planets, 5625)\n",
    "    \n",
    "    Return value:\n",
    "    df: DataFrame of shape (n_planets, 2)\n",
    "    \"\"\"\n",
    "    obscured = f_raw[:, 23500:44000].mean(axis=1)\n",
    "    unobscured = (f_raw[:, :20500].mean(axis=1) + f_raw[:, 47000:].mean(axis=1)) / 2\n",
    "    f_relative_reduction = (unobscured - obscured) / unobscured\n",
    "    \n",
    "    half_obscured1 = f_raw[:, 20500:23500].mean(axis=1)\n",
    "    half_obscured2 = f_raw[:, 44000:47000].mean(axis=1)\n",
    "    f_half_reduction1 = (unobscured - half_obscured1) / unobscured\n",
    "    f_half_reduction2 = (unobscured - half_obscured2) / unobscured\n",
    "    \n",
    "    obscured = a_raw[:, 1958:3666].mean(axis=1)\n",
    "    unobscured = (a_raw[:, :1708].mean(axis=1) + a_raw[:, 3916:].mean(axis=1)) / 2\n",
    "    a_relative_reduction = (unobscured - obscured) / unobscured\n",
    "    \n",
    "    half_obscured1 = a_raw[:, 1708:1958].mean(axis=1)\n",
    "    half_obscured2 = a_raw[:, 3666:3916].mean(axis=1)\n",
    "    a_half_reduction1 = (unobscured - half_obscured1) / unobscured\n",
    "    a_half_reduction2 = (unobscured - half_obscured2) / unobscured\n",
    "\n",
    "    df = pd.DataFrame({'a_relative_reduction': a_relative_reduction,\n",
    "                       'f_relative_reduction': f_relative_reduction,\n",
    "                      'f_half_reduction1': f_half_reduction1,\n",
    "                       'f_half_reduction2': f_half_reduction2,\n",
    "                       'a_half_reduction1': a_half_reduction1,\n",
    "                       'a_half_reduction2': a_half_reduction2\n",
    "                      \n",
    "                      })\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "878c2339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'postprocessing\n",
    "def postprocessing(pred_array, index, sigma_pred):\n",
    "    \"\"\"Create a submission dataframe from its components\n",
    "    \n",
    "    Parameters:\n",
    "    pred_array: ndarray of shape (n_samples, 283)\n",
    "    index: pandas.Index of length n_samples with name 'planet_id'\n",
    "    sigma_pred: float\n",
    "    \n",
    "    Return value:\n",
    "    df: DataFrame of shape (n_samples, 566) with planet_id as index\n",
    "    \"\"\"\n",
    "    return pd.concat([pd.DataFrame(pred_array.clip(0, None), index=index, columns=wavelengths.columns),\n",
    "                      pd.DataFrame(sigma_pred, index=index, columns=[f\"sigma_{i}\" for i in range(1, 284)])],\n",
    "                     axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f181fab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "The system cannot find the path specified. (os error 3): G:\\data\\ariel-data-challenge-2024/{dataset}/{planet_id}/FGS1_signal.parquet",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m wavelengths \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mariel-data-challenge-2024/wavelengths.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m test_adc_info \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mariel-data-challenge-2024/test_adc_info.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      4\u001b[0m                            index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplanet_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m f_raw_test \u001b[38;5;241m=\u001b[39m \u001b[43mf_read_and_preprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_adc_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_adc_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m a_raw_test \u001b[38;5;241m=\u001b[39m a_read_and_preprocess(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, test_adc_info, test_adc_info\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m      7\u001b[0m test \u001b[38;5;241m=\u001b[39m feature_engineering(f_raw_test, a_raw_test)\n",
      "Cell \u001b[1;32mIn[3], line 17\u001b[0m, in \u001b[0;36mf_read_and_preprocess\u001b[1;34m(dataset, adc_info, planet_ids)\u001b[0m\n\u001b[0;32m     15\u001b[0m f_raw_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull((\u001b[38;5;28mlen\u001b[39m(planet_ids), \u001b[38;5;241m67500\u001b[39m), np\u001b[38;5;241m.\u001b[39mnan, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, planet_id \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(planet_ids))):\n\u001b[1;32m---> 17\u001b[0m     f_signal \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mG:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mariel-data-challenge-2024/\u001b[39;49m\u001b[38;5;132;43;01m{dataset}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{planet_id}\u001b[39;49;00m\u001b[38;5;124;43m/FGS1_signal.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     mean_signal \u001b[38;5;241m=\u001b[39m f_signal\u001b[38;5;241m.\u001b[39mcast(pl\u001b[38;5;241m.\u001b[39mInt32)\u001b[38;5;241m.\u001b[39msum_horizontal()\u001b[38;5;241m.\u001b[39mcast(pl\u001b[38;5;241m.\u001b[39mFloat32)\u001b[38;5;241m.\u001b[39mto_numpy() \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;66;03m# mean over the 32*32 pixels\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     net_signal \u001b[38;5;241m=\u001b[39m mean_signal[\u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m mean_signal[\u001b[38;5;241m0\u001b[39m::\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\polars\\_utils\\deprecation.py:91\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m     88\u001b[0m     _rename_keyword_argument(\n\u001b[0;32m     89\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, version\n\u001b[0;32m     90\u001b[0m     )\n\u001b[1;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\polars\\_utils\\deprecation.py:91\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m     88\u001b[0m     _rename_keyword_argument(\n\u001b[0;32m     89\u001b[0m         old_name, new_name, kwargs, function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m, version\n\u001b[0;32m     90\u001b[0m     )\n\u001b[1;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\polars\\io\\parquet\\functions.py:208\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(source, columns, n_rows, row_index_name, row_index_offset, parallel, use_statistics, hive_partitioning, glob, hive_schema, try_parse_hive_dates, rechunk, low_memory, storage_options, retries, use_pyarrow, pyarrow_options, memory_map)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m         lf \u001b[38;5;241m=\u001b[39m lf\u001b[38;5;241m.\u001b[39mselect(columns)\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tens\\lib\\site-packages\\polars\\lazyframe\\frame.py:2027\u001b[0m, in \u001b[0;36mLazyFrame.collect\u001b[1;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, no_optimization, streaming, engine, background, _eager, **_kwargs)\u001b[0m\n\u001b[0;32m   2025\u001b[0m \u001b[38;5;66;03m# Only for testing purposes\u001b[39;00m\n\u001b[0;32m   2026\u001b[0m callback \u001b[38;5;241m=\u001b[39m _kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost_opt_callback\u001b[39m\u001b[38;5;124m\"\u001b[39m, callback)\n\u001b[1;32m-> 2027\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap_df(\u001b[43mldf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: The system cannot find the path specified. (os error 3): G:\\data\\ariel-data-challenge-2024/{dataset}/{planet_id}/FGS1_signal.parquet"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "wavelengths = pd.read_csv(r'G:\\data\\ariel-data-challenge-2024/wavelengths.csv')\n",
    "test_adc_info = pd.read_csv(r'G:\\data\\ariel-data-challenge-2024/test_adc_info.csv',\n",
    "                           index_col='planet_id')\n",
    "f_raw_test = f_read_and_preprocess('test', test_adc_info, test_adc_info.index)\n",
    "a_raw_test = a_read_and_preprocess('test', test_adc_info, test_adc_info.index)\n",
    "test = feature_engineering(f_raw_test, a_raw_test)\n",
    "\n",
    "# Load the model\n",
    "with open(directory + 'model.pickle', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "with open(directory + 'sigma_pred.pickle', 'rb') as f:\n",
    "    sigma_pred = pickle.load(f)\n",
    "    \n",
    "# Predict\n",
    "test_pred = model.predict(test)\n",
    "\n",
    "# Package into submission file\n",
    "sub_df = postprocessing(test_pred,\n",
    "                        test_adc_info.index,\n",
    "                        sigma_pred=np.tile(np.where(test_adc_info[['star']] <= 1, sigma_pred, 0.001), (1, 283)))\n",
    "display(sub_df)\n",
    "sub_df.to_csv('submission.csv')\n",
    "#!head submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ad4237",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdc8389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93b9ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1528c98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ca98ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce3d014",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a91497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41ca22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44545de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc39cdeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9606a229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60472441",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7931722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
