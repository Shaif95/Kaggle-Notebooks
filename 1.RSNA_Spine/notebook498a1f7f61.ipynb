{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":71549,"databundleVersionId":8561470,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# packages\n\n# standard\nimport numpy as np\nimport pandas as pd\nimport os\nimport time\n\n# plots\nimport plotly.express as px\nimport seaborn as sns\n\n# dicom\nimport pydicom as dicom\nfrom sklearn.model_selection import train_test_split\n\n# read data\ndf_train_main = pd.read_csv('../input/rsna-2024-lumbar-spine-degenerative-classification/train.csv')\ndf_train_label = pd.read_csv('../input/rsna-2024-lumbar-spine-degenerative-classification/train_label_coordinates.csv')\ndf_train_desc = pd.read_csv('../input/rsna-2024-lumbar-spine-degenerative-classification/train_series_descriptions.csv')\ndf_test_desc = pd.read_csv('../input/rsna-2024-lumbar-spine-degenerative-classification/test_series_descriptions.csv')\ndf_sub = pd.read_csv('../input/rsna-2024-lumbar-spine-degenerative-classification/sample_submission.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-10T04:03:25.209749Z","iopub.execute_input":"2024-06-10T04:03:25.210716Z","iopub.status.idle":"2024-06-10T04:03:26.864816Z","shell.execute_reply.started":"2024-06-10T04:03:25.210686Z","shell.execute_reply":"2024-06-10T04:03:26.863968Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport pydicom\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Input, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tqdm import tqdm\n\n# Function to load and preprocess test images\ndef load_and_preprocess_images(image_dir, unique_id, series_descriptions_df, target_size=(48, 48), images_per_type=5):\n    images = []\n    descriptions = [\"Sagittal T1\", \"Sagittal T2/STIR\", \"Axial T2\"]\n    study_data = series_descriptions_df[series_descriptions_df['study_id'] == int(unique_id)]\n    \n    for description in descriptions:\n        series = study_data[study_data['series_description'] == description]\n        if not series.empty:\n            series_id = series.iloc[0]['series_id']\n            folder_path = os.path.join(image_dir, unique_id, str(series_id))\n            if os.path.exists(folder_path):\n                files = [f for f in os.listdir(folder_path) if f.endswith('.dcm')]\n                if len(files) >= images_per_type:\n                    selected_files = np.random.choice(files, images_per_type, replace=False)\n                else:\n                    selected_files = files + [None] * (images_per_type - len(files))\n                \n                for file in selected_files:\n                    if file:\n                        image_path = os.path.join(folder_path, file)\n                        try:\n                            # Load DICOM image\n                            dicom = pydicom.dcmread(image_path)\n                            image = dicom.pixel_array\n\n                            # Convert image to uint8 if necessary\n                            if image.dtype != np.uint8:\n                                image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n                            image = cv2.resize(image, target_size)\n                            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)  # Convert to RGB\n\n                            images.append(image)\n                        except Exception as e:\n                            print(f\"Error loading image {image_path}: {e}\")\n                            images.append(np.zeros((target_size[0], target_size[1], 3), dtype=np.float32))\n                    else:\n                        images.append(np.zeros((target_size[0], target_size[1], 3), dtype=np.float32))\n            else:\n                images.extend([np.zeros((target_size[0], target_size[1], 3), dtype=np.float32)] * images_per_type)\n        else:\n            images.extend([np.zeros((target_size[0], target_size[1], 3), dtype=np.float32)] * images_per_type)\n    \n    images = np.array(images).astype('float32') / 255.0\n    return images\n\n# Load all data and preprocess\ndef load_data(df, series_descriptions_df, image_dir, target_size=(48, 48), images_per_type=5):\n    x_data = []\n    y_data = []\n    label_mapping = {\n        \"Normal/Mild\": [0.6, 0.2, 0.2],\n        \"Moderate\": [0.2, 0.6, 0.2],\n        \"Severe\": [0.2, 0.2, 0.6]\n    }\n    x = 0\n    for _, row in tqdm(df.iterrows(), total=len(df)):\n        study_id = row['study_id']\n        try:\n            images = load_and_preprocess_images(image_dir, str(study_id), series_descriptions_df, target_size, images_per_type)\n            x_data.append(images)\n\n            labels = {}\n            for condition in df.columns[1:]:\n                original_label = row[condition]\n                if not pd.isna(original_label):\n                    labels[condition] = label_mapping.get(original_label, None)\n\n            y_data.append(labels)\n        except Exception as e:\n            print(f\"Error processing study_id {study_id}: {e}\")\n            continue\n\n    return np.array(x_data), y_data\n\n# Load the DataFrame\ndf_train_main = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train.csv')\ndf_train_desc = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_series_descriptions.csv')\nimage_dir = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images'\n\n# Load the entire dataset\nx_train, y_train = load_data(df_train_main, df_train_desc, image_dir, images_per_type=5)\nprint(\"Data Loaded\")\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T04:56:19.583608Z","iopub.execute_input":"2024-06-10T04:56:19.584005Z","iopub.status.idle":"2024-06-10T04:56:43.204107Z","shell.execute_reply.started":"2024-06-10T04:56:19.583977Z","shell.execute_reply":"2024-06-10T04:56:43.203097Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"  5%|▌         | 100/1975 [00:23<07:21,  4.24it/s]","output_type":"stream"},{"name":"stdout","text":"Data Loaded\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Define the function to train the model for a specific condition\ndef train_condition_model(condition_name, x_train, y_train, image_size=(48, 48), epochs=2, batch_size=10, label_mapping=None, default='yes'):\n    # Default label mapping\n    default_label_mapping = {\n        \"Normal/Mild\": [0.6, 0.2, 0.2],\n        \"Moderate\": [0.2, 0.6, 0.2],\n        \"Severe\": [0.2, 0.2, 0.6]\n    }\n\n    # Use default label mapping if not provided or if default is set to 'yes'\n    if default == 'yes' or label_mapping is None:\n        label_mapping = default_label_mapping\n\n    # Convert all labels in y_train based on the provided mapping\n    y_converted = []\n    for labels in y_train:\n        if condition_name in labels:\n            original_label = tuple(labels[condition_name])  # Convert list to tuple\n            mapped_label = label_mapping.get(original_label, default_label_mapping.get(original_label))\n            if mapped_label is not None:\n                y_converted.append(mapped_label)\n            else:\n                y_converted.append(labels[condition_name])\n        else:\n            y_converted.append([0, 0, 0])  # Fallback if condition_name not in labels\n\n    x_filtered = np.array(x_train)\n    y_filtered = np.array(y_converted)\n\n    # Define the CNN-LSTM model with smaller filter sizes and LSTM units\n    def create_model(input_shape):\n        model = Sequential()\n        model.add(Input(shape=input_shape))\n        model.add(TimeDistributed(Conv2D(4, (3, 3), activation='relu')))\n        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n        model.add(TimeDistributed(Conv2D(4, (3, 3), activation='relu')))\n        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n        model.add(TimeDistributed(Conv2D(8, (3, 3), activation='relu')))\n        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n        model.add(TimeDistributed(Flatten()))\n        model.add(Dropout(0.5))\n        model.add(LSTM(100))\n        model.add(Dense(3, activation='softmax'))\n\n        model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n        return model\n\n    # Prepare the training and validation data\n    split_index = int(0.9 * len(x_filtered))\n    x_train_split, x_val_split = x_filtered[:split_index], x_filtered[split_index:]\n    y_train_split, y_val_split = y_filtered[:split_index], y_filtered[split_index:]\n\n    # Create the model\n    input_shape = (15, image_size[0], image_size[1], 3)\n    model = create_model(input_shape)\n\n    # Train the model\n    model.fit(x_train_split, y_train_split, validation_data=(x_val_split, y_val_split), epochs=epochs, batch_size=batch_size)\n\n    return model\n\n# Example usage with default label mapping\ncondition_name = 'spinal_canal_stenosis_l1_l2'\nmodel = train_condition_model(condition_name, x_train, y_train, image_size=(48, 48), epochs=1, batch_size=10)\n\n# Example usage with custom label mapping\ncustom_label_mapping = {\n    \"Normal/Mild\": [0.4, 0.3, 0.3],\n    \"Moderate\": [0.3, 0.4, 0.3],\n    \"Severe\": [0.3, 0.3, 0.4]\n}\nmodel = train_condition_model('left_neural_foraminal_narrowing_l4_l5', x_train, y_train, image_size=(48, 48), epochs=1, batch_size=10, label_mapping=custom_label_mapping, default='no')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-10T04:56:45.365522Z","iopub.execute_input":"2024-06-10T04:56:45.365927Z","iopub.status.idle":"2024-06-10T04:56:58.672168Z","shell.execute_reply.started":"2024-06-10T04:56:45.365898Z","shell.execute_reply":"2024-06-10T04:56:58.671402Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 143ms/step - accuracy: 0.7799 - loss: 1.0205 - val_accuracy: 1.0000 - val_loss: 0.9591\n\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - accuracy: 0.4993 - loss: 1.0870 - val_accuracy: 0.6000 - val_loss: 1.0798\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-09T03:25:58.239622Z","iopub.execute_input":"2024-06-09T03:25:58.240172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of conditions\nconditions = [\n    'left_neural_foraminal_narrowing_l1_l2',\n    'left_neural_foraminal_narrowing_l2_l3',\n    'left_neural_foraminal_narrowing_l3_l4',\n    'left_neural_foraminal_narrowing_l5_s1',\n    'left_subarticular_stenosis_l1_l2',\n    'left_subarticular_stenosis_l2_l3',\n    'right_neural_foraminal_narrowing_l1_l2',\n    'right_neural_foraminal_narrowing_l2_l3',\n    'right_neural_foraminal_narrowing_l3_l4',\n    'right_neural_foraminal_narrowing_l5_s1',\n    'right_subarticular_stenosis_l1_l2',\n    'right_subarticular_stenosis_l2_l3',\n    'right_subarticular_stenosis_l3_l4',\n    'right_subarticular_stenosis_l5_s1',\n    'spinal_canal_stenosis_l1_l2',\n    'spinal_canal_stenosis_l2_l3',\n    'spinal_canal_stenosis_l3_l4',\n    'spinal_canal_stenosis_l4_l5',\n    'spinal_canal_stenosis_l5_s1'\n]\n\n# Custom label mapping for specific conditions\ncustom_label_mapping = {\n    \"Normal/Mild\": [0.4, 0.3, 0.3],\n    \"Moderate\": [0.3, 0.4, 0.3],\n    \"Severe\": [0.3, 0.3, 0.4]\n}\n\n# Conditions to use the custom label mapping\ncustom_conditions = [\n    'left_neural_foraminal_narrowing_l4_l5',\n    'left_subarticular_stenosis_l3_l4',\n    'left_subarticular_stenosis_l4_l5',\n    'left_subarticular_stenosis_l5_s1',\n    'right_neural_foraminal_narrowing_l4_l5',\n    'right_subarticular_stenosis_l4_l5'\n]\n\n# Train one model for each condition\ntrained_models = {}\n\nfor condition in conditions:\n    print(f\"Training model for condition: {condition}\")\n    if condition in custom_conditions:\n        model = train_condition_model(condition, x_train, y_train, ids, df_train_label, image_size=(48, 48), epochs=5, batch_size=10, label_mapping=custom_label_mapping, default='no')\n    else:\n        model = train_condition_model(condition, x_train, y_train, ids, df_train_label, image_size=(48, 48), epochs=5, batch_size=10)\n    trained_models[condition] = model\n\nprint(\"Training complete for all conditions.\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\n# Assuming x_train and y_train are already defined\ndel x_train\ndel y_train\n# Explicitly run garbage collection to free up memory\ngc.collect()\nprint(\"x_train and y_train deleted, and memory freed using gc.collect()\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport pydicom\nimport cv2\n\n# Define the path to your test images directory\ntest_images_dir = \"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images\"\n\n# Load the test series descriptions\ndf_test_desc = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_series_descriptions.csv')\n\n# Function to load and preprocess test images\ndef load_and_preprocess_images(image_dir, unique_id, series_descriptions_df, target_size=(48,48), images_per_type=5):\n    images = []\n    descriptions = [\"Sagittal T1\", \"Sagittal T2/STIR\", \"Axial T2\"]\n    study_data = series_descriptions_df[series_descriptions_df['study_id'] == int(unique_id)]\n    \n    for description in descriptions:\n        series = study_data[study_data['series_description'] == description]\n        if not series.empty:\n            series_id = series.iloc[0]['series_id']\n            folder_path = os.path.join(image_dir, unique_id, str(series_id))\n            if os.path.exists(folder_path):\n                files = [f for f in os.listdir(folder_path) if f.endswith('.dcm')]\n                if len(files) >= images_per_type:\n                    selected_files = np.random.choice(files, images_per_type, replace=False)\n                else:\n                    selected_files = files + [None] * (images_per_type - len(files))\n                \n                for file in selected_files:\n                    if file:\n                        image_path = os.path.join(folder_path, file)\n                        try:\n                            # Load DICOM image\n                            dicom = pydicom.dcmread(image_path)\n                            image = dicom.pixel_array\n\n                            # Convert image to uint8 if necessary\n                            if image.dtype != np.uint8:\n                                image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n                            image = cv2.resize(image, target_size)\n                            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)  # Convert to RGB\n\n                            images.append(image)\n                        except Exception as e:\n                            print(f\"Error loading image {image_path}: {e}\")\n                            images.append(np.zeros((target_size[0], target_size[1], 3), dtype=np.float32))\n                    else:\n                        images.append(np.zeros((target_size[0], target_size[1], 3), dtype=np.float32))\n            else:\n                images.extend([np.zeros((target_size[0], target_size[1], 3), dtype=np.float32)] * images_per_type)\n        else:\n            images.extend([np.zeros((target_size[0], target_size[1], 3), dtype=np.float32)] * images_per_type)\n    \n    images = np.array(images).astype('float32') / 255.0\n    return images\n\n# List of conditions\nconditions = ['left_neural_foraminal_narrowing_l1_l2',\n              'left_neural_foraminal_narrowing_l2_l3',\n              'left_neural_foraminal_narrowing_l3_l4',\n              'left_neural_foraminal_narrowing_l4_l5',\n              'left_neural_foraminal_narrowing_l5_s1',\n              'left_subarticular_stenosis_l1_l2',\n              'left_subarticular_stenosis_l2_l3',\n              'left_subarticular_stenosis_l3_l4',\n              'left_subarticular_stenosis_l4_l5',\n              'left_subarticular_stenosis_l5_s1',\n              'right_neural_foraminal_narrowing_l1_l2',\n              'right_neural_foraminal_narrowing_l2_l3',\n              'right_neural_foraminal_narrowing_l3_l4',\n              'right_neural_foraminal_narrowing_l4_l5',\n              'right_neural_foraminal_narrowing_l5_s1',\n              'right_subarticular_stenosis_l1_l2',\n              'right_subarticular_stenosis_l2_l3',\n              'right_subarticular_stenosis_l3_l4',\n              'right_subarticular_stenosis_l4_l5',\n              'right_subarticular_stenosis_l5_s1',\n              'spinal_canal_stenosis_l1_l2',\n              'spinal_canal_stenosis_l2_l3',\n              'spinal_canal_stenosis_l3_l4',\n              'spinal_canal_stenosis_l4_l5',\n              'spinal_canal_stenosis_l5_s1']\n\n# Get all unique IDs from the test images directory\nunique_ids = [folder for folder in os.listdir(test_images_dir) if os.path.isdir(os.path.join(test_images_dir, folder))]\n\n# Generate the row_ids needed for submission by repeating each unique_id for each condition\nrow_ids = [f\"{id}_{condition}\" for id in unique_ids for condition in conditions]\n\n# Create the submission DataFrame\ndf_submission = pd.DataFrame(row_ids, columns=['row_id'])\ndf_submission['normal_mild'] = 0.333333\ndf_submission['moderate'] = 0.333333\ndf_submission['severe'] = 0.333333\n\n# Iterate over each unique ID and each condition to make predictions\nfor unique_id in unique_ids:\n    for condition in conditions:\n        row_id = f\"{unique_id}_{condition}\"\n        try:\n            # Load and preprocess test images\n            images = load_and_preprocess_images(test_images_dir, unique_id, df_test_desc, images_per_type=5)\n\n            # Get the corresponding trained model\n            model = trained_models[condition]\n\n            # Make prediction\n            prediction = model.predict(np.expand_dims(images, axis=0))\n\n            # Update the submission DataFrame\n            df_submission.loc[df_submission['row_id'] == row_id, ['normal_mild', 'moderate', 'severe']] = prediction[0]\n        except Exception as e:\n            print(f\"Error processing {row_id}: {e}\")\n\nprint(df_submission.head())\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-06-09T02:47:05.933296Z","iopub.execute_input":"2024-06-09T02:47:05.934161Z","iopub.status.idle":"2024-06-09T02:47:05.939764Z","shell.execute_reply.started":"2024-06-09T02:47:05.934126Z","shell.execute_reply":"2024-06-09T02:47:05.938417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"m","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}