{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T20:31:29.372988Z",
     "iopub.status.busy": "2024-06-03T20:31:29.372554Z",
     "iopub.status.idle": "2024-06-03T20:31:33.398845Z",
     "shell.execute_reply": "2024-06-03T20:31:33.397704Z",
     "shell.execute_reply.started": "2024-06-03T20:31:29.372939Z"
    }
   },
   "outputs": [],
   "source": [
    "# packages\n",
    "\n",
    "# standard\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "# plots\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "# dicom\n",
    "import pydicom as dicom\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T20:31:37.220178Z",
     "iopub.status.busy": "2024-06-03T20:31:37.219372Z",
     "iopub.status.idle": "2024-06-03T20:31:37.433012Z",
     "shell.execute_reply": "2024-06-03T20:31:37.431754Z",
     "shell.execute_reply.started": "2024-06-03T20:31:37.220144Z"
    }
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "df_train_main = pd.read_csv('../input/rsna-2024-lumbar-spine-degenerative-classification/train.csv')\n",
    "df_train_label = pd.read_csv('../input/rsna-2024-lumbar-spine-degenerative-classification/train_label_coordinates.csv')\n",
    "df_train_desc = pd.read_csv('../input/rsna-2024-lumbar-spine-degenerative-classification/train_series_descriptions.csv')\n",
    "df_test_desc = pd.read_csv('../input/rsna-2024-lumbar-spine-degenerative-classification/test_series_descriptions.csv')\n",
    "df_sub = pd.read_csv('../input/rsna-2024-lumbar-spine-degenerative-classification/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-22T23:35:30.720213Z",
     "iopub.status.busy": "2024-05-22T23:35:30.719135Z",
     "iopub.status.idle": "2024-05-22T23:35:30.794270Z",
     "shell.execute_reply": "2024-05-22T23:35:30.793224Z",
     "shell.execute_reply.started": "2024-05-22T23:35:30.720164Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to load and preprocess test images\n",
    "def load_and_preprocess_images(image_dir, unique_id, target_size=(32, 32), images_per_batch=5):\n",
    "    images = []\n",
    "    subfolders = [f.path for f in os.scandir(os.path.join(image_dir, unique_id)) if f.is_dir()]\n",
    "\n",
    "    for folder in subfolders:\n",
    "        files = [f for f in os.listdir(folder) if f.endswith('.dcm')]\n",
    "        for file in files:\n",
    "            image_path = os.path.join(folder, file)\n",
    "            try:\n",
    "                # Load DICOM image\n",
    "                dicom = pydicom.dcmread(image_path)\n",
    "                image = dicom.pixel_array\n",
    "\n",
    "                # Convert image to uint8 if necessary\n",
    "                if image.dtype != np.uint8:\n",
    "                    image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "                image = cv2.resize(image, target_size)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)  # Convert to RGB\n",
    "\n",
    "                images.append(image)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {image_path}: {e}\")\n",
    "\n",
    "    # If fewer than required images, use padding\n",
    "    if len(images) < images_per_batch:\n",
    "        padding = [np.zeros((target_size[0], target_size[1], 3), dtype=np.float32)] * (images_per_batch - len(images))\n",
    "        images.extend(padding)\n",
    "    else:\n",
    "        images = sorted(images, key=lambda x: np.random.random())[:images_per_batch]\n",
    "\n",
    "    images = np.array(images).astype('float32') / 255.0\n",
    "    return images\n",
    "\n",
    "# Load all data and preprocess\n",
    "def load_data(df, image_dir, target_size=(32, 32), images_per_batch=5):\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    label_mapping = {\n",
    "        \"Normal/Mild\": [0.5, 0.25, 0.25],\n",
    "        \"Moderate\": [0.25, 0.5, 0.25],\n",
    "        \"Severe\": [0.25, 0.25, 0.5]\n",
    "    }\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        study_id = row['study_id']\n",
    "        images = load_and_preprocess_images(image_dir, str(study_id), target_size, images_per_batch)\n",
    "        x_data.append(images)\n",
    "\n",
    "        labels = {}\n",
    "        for condition in df.columns[1:]:\n",
    "            original_label = row[condition]\n",
    "            if not pd.isna(original_label):\n",
    "                labels[condition] = label_mapping.get(original_label, None)\n",
    "\n",
    "        y_data.append(labels)\n",
    "\n",
    "    return np.array(x_data), y_data\n",
    "\n",
    "# Define the function to train the model for a specific condition\n",
    "def train_condition_model(condition_name, x_train, y_train, image_size=(32, 32), epochs=2, batch_size=10):\n",
    "    # Filter the labels based on the condition and ensure both x_train and y_filtered are of the same length\n",
    "    filtered_data = [(x, labels[condition_name]) for x, labels in zip(x_train, y_train) if condition_name in labels]\n",
    "    x_filtered, y_filtered = zip(*filtered_data)\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    x_filtered = np.array(x_filtered)\n",
    "    y_filtered = np.array(y_filtered)\n",
    "\n",
    "    # Define the CNN-LSTM model with smaller filter sizes and LSTM units\n",
    "    def create_model(input_shape):\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=input_shape))\n",
    "        model.add(TimeDistributed(Conv2D(4, (3, 3), activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(4, (3, 3), activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        model.add(TimeDistributed(Conv2D(8, (3, 3), activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        model.add(LSTM(50))\n",
    "        model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "        model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    # Prepare the training and validation data\n",
    "    split_index = int(0.9 * len(x_filtered))\n",
    "    x_train_split, x_val_split = x_filtered[:split_index], x_filtered[split_index:]\n",
    "    y_train_split, y_val_split = y_filtered[:split_index], y_filtered[split_index:]\n",
    "\n",
    "    # Create the model\n",
    "    input_shape = (5, image_size[0], image_size[1], 3)\n",
    "    model = create_model(input_shape)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(x_train_split, y_train_split, validation_data=(x_val_split, y_val_split), epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load the DataFrame\n",
    "df_train_main = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train.csv')\n",
    "image_dir = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images'\n",
    "\n",
    "# Load the entire dataset\n",
    "x_train, y_train = load_data(df_train_main, image_dir, images_per_batch=5)\n",
    "print(\"Data Loaded\")\n",
    "\n",
    "# Example usage\n",
    "condition_name = 'spinal_canal_stenosis_l1_l2'\n",
    "model = train_condition_model(condition_name, x_train, y_train, image_size=(32, 32), epochs=1, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-27T19:52:56.292761Z",
     "iopub.status.busy": "2024-05-27T19:52:56.292352Z",
     "iopub.status.idle": "2024-05-27T19:52:56.477653Z",
     "shell.execute_reply": "2024-05-27T19:52:56.476278Z",
     "shell.execute_reply.started": "2024-05-27T19:52:56.292730Z"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T22:30:15.332131Z",
     "iopub.status.busy": "2024-06-03T22:30:15.331429Z",
     "iopub.status.idle": "2024-06-03T22:34:37.766847Z",
     "shell.execute_reply": "2024-06-03T22:34:37.765525Z",
     "shell.execute_reply.started": "2024-06-03T22:30:15.332092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for condition: left_neural_foraminal_narrowing_l1_l2\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.9569 - loss: 1.0522 - val_accuracy: 0.9848 - val_loss: 1.0425\n",
      "Training model for condition: left_neural_foraminal_narrowing_l2_l3\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.7667 - loss: 1.0685 - val_accuracy: 0.9343 - val_loss: 1.0513\n",
      "Training model for condition: left_neural_foraminal_narrowing_l3_l4\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.7503 - loss: 1.0741 - val_accuracy: 0.7879 - val_loss: 1.0693\n",
      "Training model for condition: left_neural_foraminal_narrowing_l4_l5\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.5732 - loss: 1.0869 - val_accuracy: 0.6566 - val_loss: 1.0809\n",
      "Training model for condition: left_neural_foraminal_narrowing_l5_s1\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.6195 - loss: 1.0882 - val_accuracy: 0.6768 - val_loss: 1.0815\n",
      "Training model for condition: left_subarticular_stenosis_l1_l2\n",
      "\u001b[1m163/163\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.9231 - loss: 1.0566 - val_accuracy: 0.9451 - val_loss: 1.0495\n",
      "Training model for condition: left_subarticular_stenosis_l2_l3\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - accuracy: 0.7255 - loss: 1.0774 - val_accuracy: 0.8737 - val_loss: 1.0600\n",
      "Training model for condition: left_subarticular_stenosis_l3_l4\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.6445 - loss: 1.0848 - val_accuracy: 0.6869 - val_loss: 1.0801\n",
      "Training model for condition: left_subarticular_stenosis_l4_l5\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.4264 - loss: 1.0973 - val_accuracy: 0.4343 - val_loss: 1.0966\n",
      "Training model for condition: left_subarticular_stenosis_l5_s1\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.6792 - loss: 1.0821 - val_accuracy: 0.6954 - val_loss: 1.0807\n",
      "Training model for condition: right_neural_foraminal_narrowing_l1_l2\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 31ms/step - accuracy: 0.9483 - loss: 1.0543 - val_accuracy: 0.9746 - val_loss: 1.0444\n",
      "Training model for condition: right_neural_foraminal_narrowing_l2_l3\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.8796 - loss: 1.0602 - val_accuracy: 0.9289 - val_loss: 1.0526\n",
      "Training model for condition: right_neural_foraminal_narrowing_l3_l4\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.7293 - loss: 1.0765 - val_accuracy: 0.8274 - val_loss: 1.0656\n",
      "Training model for condition: right_neural_foraminal_narrowing_l4_l5\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 32ms/step - accuracy: 0.5865 - loss: 1.0873 - val_accuracy: 0.6904 - val_loss: 1.0810\n",
      "Training model for condition: right_neural_foraminal_narrowing_l5_s1\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.6360 - loss: 1.0865 - val_accuracy: 0.6802 - val_loss: 1.0820\n",
      "Training model for condition: right_subarticular_stenosis_l1_l2\n",
      "\u001b[1m164/164\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - accuracy: 0.8643 - loss: 1.0621 - val_accuracy: 0.9231 - val_loss: 1.0524\n",
      "Training model for condition: right_subarticular_stenosis_l2_l3\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.7967 - loss: 1.0696 - val_accuracy: 0.8526 - val_loss: 1.0618\n",
      "Training model for condition: right_subarticular_stenosis_l3_l4\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.6476 - loss: 1.0858 - val_accuracy: 0.7323 - val_loss: 1.0771\n",
      "Training model for condition: right_subarticular_stenosis_l4_l5\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - accuracy: 0.4203 - loss: 1.0971 - val_accuracy: 0.4747 - val_loss: 1.0952\n",
      "Training model for condition: right_subarticular_stenosis_l5_s1\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.6758 - loss: 1.0835 - val_accuracy: 0.7919 - val_loss: 1.0726\n",
      "Training model for condition: spinal_canal_stenosis_l1_l2\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.8954 - loss: 1.0577 - val_accuracy: 0.9596 - val_loss: 1.0467\n",
      "Training model for condition: spinal_canal_stenosis_l2_l3\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 36ms/step - accuracy: 0.8382 - loss: 1.0655 - val_accuracy: 0.9040 - val_loss: 1.0549\n",
      "Training model for condition: spinal_canal_stenosis_l3_l4\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 31ms/step - accuracy: 0.8316 - loss: 1.0706 - val_accuracy: 0.8687 - val_loss: 1.0626\n",
      "Training model for condition: spinal_canal_stenosis_l4_l5\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 32ms/step - accuracy: 0.7242 - loss: 1.0799 - val_accuracy: 0.7727 - val_loss: 1.0723\n",
      "Training model for condition: spinal_canal_stenosis_l5_s1\n",
      "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 32ms/step - accuracy: 0.8968 - loss: 1.0550 - val_accuracy: 0.9596 - val_loss: 1.0465\n",
      "Training complete for all conditions.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# List of conditions\n",
    "conditions = ['left_neural_foraminal_narrowing_l1_l2',\n",
    "              'left_neural_foraminal_narrowing_l2_l3',\n",
    "              'left_neural_foraminal_narrowing_l3_l4',\n",
    "              'left_neural_foraminal_narrowing_l4_l5',\n",
    "              'left_neural_foraminal_narrowing_l5_s1',\n",
    "              'left_subarticular_stenosis_l1_l2',\n",
    "              'left_subarticular_stenosis_l2_l3',\n",
    "              'left_subarticular_stenosis_l3_l4',\n",
    "              'left_subarticular_stenosis_l4_l5',\n",
    "              'left_subarticular_stenosis_l5_s1',\n",
    "              'right_neural_foraminal_narrowing_l1_l2',\n",
    "              'right_neural_foraminal_narrowing_l2_l3',\n",
    "              'right_neural_foraminal_narrowing_l3_l4',\n",
    "              'right_neural_foraminal_narrowing_l4_l5',\n",
    "              'right_neural_foraminal_narrowing_l5_s1',\n",
    "              'right_subarticular_stenosis_l1_l2',\n",
    "              'right_subarticular_stenosis_l2_l3',\n",
    "              'right_subarticular_stenosis_l3_l4',\n",
    "              'right_subarticular_stenosis_l4_l5',\n",
    "              'right_subarticular_stenosis_l5_s1',\n",
    "              'spinal_canal_stenosis_l1_l2',\n",
    "              'spinal_canal_stenosis_l2_l3',\n",
    "              'spinal_canal_stenosis_l3_l4',\n",
    "              'spinal_canal_stenosis_l4_l5',\n",
    "              'spinal_canal_stenosis_l5_s1']\n",
    "\n",
    "# Train one model for each condition\n",
    "trained_models = {}\n",
    "\n",
    "for condition in conditions:\n",
    "    print(f\"Training model for condition: {condition}\")\n",
    "    model = train_condition_model(condition, x_train, y_train, image_size=(32, 32), epochs=1, batch_size=10)\n",
    "    trained_models[condition] = model\n",
    "\n",
    "print(\"Training complete for all conditions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T22:35:24.271936Z",
     "iopub.status.busy": "2024-06-03T22:35:24.271494Z",
     "iopub.status.idle": "2024-06-03T22:36:34.628441Z",
     "shell.execute_reply": "2024-06-03T22:36:34.627252Z",
     "shell.execute_reply.started": "2024-06-03T22:35:24.271890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 521ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step\n",
      "                                           row_id  normal_mild  moderate  \\\n",
      "0  44036939_left_neural_foraminal_narrowing_l1_l2     0.494151  0.254710   \n",
      "1  44036939_left_neural_foraminal_narrowing_l2_l3     0.460229  0.289706   \n",
      "2  44036939_left_neural_foraminal_narrowing_l3_l4     0.435318  0.304059   \n",
      "3  44036939_left_neural_foraminal_narrowing_l4_l5     0.401943  0.330438   \n",
      "4  44036939_left_neural_foraminal_narrowing_l5_s1     0.408726  0.312358   \n",
      "\n",
      "     severe  \n",
      "0  0.251139  \n",
      "1  0.250064  \n",
      "2  0.260623  \n",
      "3  0.267620  \n",
      "4  0.278916  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pydicom\n",
    "import cv2\n",
    "\n",
    "# Define the path to your test images directory\n",
    "test_images_dir = \"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images\"\n",
    "\n",
    "# Function to load and preprocess test images\n",
    "def load_and_preprocess_images(image_dir, unique_id, target_size=(32, 32), images_per_batch=5):\n",
    "    images = []\n",
    "    subfolders = [f.path for f in os.scandir(os.path.join(image_dir, unique_id)) if f.is_dir()]\n",
    "\n",
    "    for folder in subfolders:\n",
    "        files = [f for f in os.listdir(folder) if f.endswith('.dcm')]\n",
    "        for file in files:\n",
    "            image_path = os.path.join(folder, file)\n",
    "            try:\n",
    "                # Load DICOM image\n",
    "                dicom = pydicom.dcmread(image_path)\n",
    "                image = dicom.pixel_array\n",
    "\n",
    "                # Convert image to uint8 if necessary\n",
    "                if image.dtype != np.uint8:\n",
    "                    image = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "                image = cv2.resize(image, target_size)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)  # Convert to RGB\n",
    "\n",
    "                images.append(image)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image {image_path}: {e}\")\n",
    "\n",
    "    # If fewer than required images, use padding\n",
    "    if len(images) < images_per_batch:\n",
    "        padding = [np.zeros((target_size[0], target_size[1], 3), dtype=np.float32)] * (images_per_batch - len(images))\n",
    "        images.extend(padding)\n",
    "    else:\n",
    "        images = sorted(images, key=lambda x: np.random.random())[:images_per_batch]\n",
    "\n",
    "    images = np.array(images).astype('float32') / 255.0\n",
    "    return images\n",
    "\n",
    "# List of conditions\n",
    "conditions = ['left_neural_foraminal_narrowing_l1_l2',\n",
    "              'left_neural_foraminal_narrowing_l2_l3',\n",
    "              'left_neural_foraminal_narrowing_l3_l4',\n",
    "              'left_neural_foraminal_narrowing_l4_l5',\n",
    "              'left_neural_foraminal_narrowing_l5_s1',\n",
    "              'left_subarticular_stenosis_l1_l2',\n",
    "              'left_subarticular_stenosis_l2_l3',\n",
    "              'left_subarticular_stenosis_l3_l4',\n",
    "              'left_subarticular_stenosis_l4_l5',\n",
    "              'left_subarticular_stenosis_l5_s1',\n",
    "              'right_neural_foraminal_narrowing_l1_l2',\n",
    "              'right_neural_foraminal_narrowing_l2_l3',\n",
    "              'right_neural_foraminal_narrowing_l3_l4',\n",
    "              'right_neural_foraminal_narrowing_l4_l5',\n",
    "              'right_neural_foraminal_narrowing_l5_s1',\n",
    "              'right_subarticular_stenosis_l1_l2',\n",
    "              'right_subarticular_stenosis_l2_l3',\n",
    "              'right_subarticular_stenosis_l3_l4',\n",
    "              'right_subarticular_stenosis_l4_l5',\n",
    "              'right_subarticular_stenosis_l5_s1',\n",
    "              'spinal_canal_stenosis_l1_l2',\n",
    "              'spinal_canal_stenosis_l2_l3',\n",
    "              'spinal_canal_stenosis_l3_l4',\n",
    "              'spinal_canal_stenosis_l4_l5',\n",
    "              'spinal_canal_stenosis_l5_s1']\n",
    "\n",
    "# Get all unique IDs from the test images directory\n",
    "unique_ids = [folder for folder in os.listdir(test_images_dir) if os.path.isdir(os.path.join(test_images_dir, folder))]\n",
    "\n",
    "# Generate the row_ids needed for submission by repeating each unique_id for each condition\n",
    "row_ids = [f\"{id}_{condition}\" for id in unique_ids for condition in conditions]\n",
    "\n",
    "# Create the submission DataFrame\n",
    "df_submission = pd.DataFrame(row_ids, columns=['row_id'])\n",
    "df_submission['normal_mild'] = 0.333333\n",
    "df_submission['moderate'] = 0.333333\n",
    "df_submission['severe'] = 0.333333\n",
    "\n",
    "# Iterate over each unique ID and each condition to make predictions\n",
    "for unique_id in unique_ids:\n",
    "    for condition in conditions:\n",
    "        row_id = f\"{unique_id}_{condition}\"\n",
    "        try:\n",
    "            # Load and preprocess test images\n",
    "            images = load_and_preprocess_images(test_images_dir, unique_id, images_per_batch=5)\n",
    "\n",
    "            # Get the corresponding trained model\n",
    "            model = trained_models[condition]\n",
    "\n",
    "            # Make prediction\n",
    "            prediction = model.predict(np.expand_dims(images, axis=0))\n",
    "\n",
    "            # Update the submission DataFrame\n",
    "            df_submission.loc[df_submission['row_id'] == row_id, ['normal_mild', 'moderate', 'severe']] = prediction[0]\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {row_id}: {e}\")\n",
    "\n",
    "print(df_submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-03T22:36:56.639282Z",
     "iopub.status.busy": "2024-06-03T22:36:56.638844Z",
     "iopub.status.idle": "2024-06-03T22:36:56.650148Z",
     "shell.execute_reply": "2024-06-03T22:36:56.648958Z",
     "shell.execute_reply.started": "2024-06-03T22:36:56.639251Z"
    }
   },
   "outputs": [],
   "source": [
    "df_submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T00:45:02.399281Z",
     "iopub.status.busy": "2024-05-28T00:45:02.398964Z",
     "iopub.status.idle": "2024-05-28T00:45:23.111670Z",
     "shell.execute_reply": "2024-05-28T00:45:23.110670Z",
     "shell.execute_reply.started": "2024-05-28T00:45:02.399255Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T00:45:23.113140Z",
     "iopub.status.busy": "2024-05-28T00:45:23.112831Z",
     "iopub.status.idle": "2024-05-28T00:45:23.121527Z",
     "shell.execute_reply": "2024-05-28T00:45:23.120436Z",
     "shell.execute_reply.started": "2024-05-28T00:45:23.113114Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T16:37:11.909153Z",
     "iopub.status.busy": "2024-05-31T16:37:11.908718Z",
     "iopub.status.idle": "2024-05-31T16:37:30.840443Z",
     "shell.execute_reply": "2024-05-31T16:37:30.839211Z",
     "shell.execute_reply.started": "2024-05-31T16:37:11.909099Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8561470,
     "sourceId": 71549,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
